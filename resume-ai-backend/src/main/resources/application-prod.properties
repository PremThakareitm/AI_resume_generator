spring.application.name=resume-ai-backend
server.port=${PORT:8080}

# AI Model Configuration - Choose one
# For Ollama (self-hosted, remove if using OpenAI)
spring.ai.ollama.chat.model=${SPRING_AI_OLLAMA_CHAT_MODEL:mistral:latest}
spring.ai.ollama.base-url=${SPRING_AI_OLLAMA_BASE_URL:http://localhost:11434}

# For OpenAI (cloud-based, uncomment if using OpenAI)
#spring.ai.openai.api-key=${SPRING_AI_OPENAI_API_KEY}
#spring.ai.openai.base-url=${SPRING_AI_OPENAI_BASE_URL:https://api.openai.com}
#spring.ai.openai.chat.model=${SPRING_AI_OPENAI_CHAT_MODEL:gpt-3.5-turbo}

# CORS Configuration - Update with your frontend URL in production
spring.mvc.cors.allowed-origins=${ALLOWED_ORIGINS:*}
spring.mvc.cors.allowed-methods=GET,POST,PUT,DELETE,OPTIONS
spring.mvc.cors.allowed-headers=*
spring.mvc.cors.allow-credentials=false
spring.mvc.cors.max-age=3600

# Server settings
server.compression.enabled=true
server.tomcat.max-threads=200
server.tomcat.max-swallow-size=2MB
